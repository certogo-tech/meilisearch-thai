# Optimized Docker Compose configuration for Thai Tokenizer
# Based on performance optimization recommendations

version: '3.8'

services:
  nginx:
    image: nginx:1.25-alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      thai-tokenizer:
        condition: service_healthy
      meilisearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - thai-tokenizer-network
    profiles:
      - production
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
      replicas: 1

  thai-tokenizer:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    ports:
      - "8000:8000"
    environment:
      # MeiliSearch connection
      - MEILISEARCH_HOST=http://meilisearch:7700
      - MEILISEARCH_API_KEY=${MEILISEARCH_API_KEY:-masterKey}
      - MEILISEARCH_INDEX=${MEILISEARCH_INDEX:-documents}
      
      # Tokenizer configuration
      - TOKENIZER_ENGINE=${TOKENIZER_ENGINE:-pythainlp}
      - TOKENIZER_MODEL=${TOKENIZER_MODEL:-}
      
      # Optimized processing configuration
      - BATCH_SIZE=25  # Optimized batch size for 63% improvement
      - MAX_RETRIES=3
      - TIMEOUT_MS=5000
      
      # Performance optimizations
      - PYTHONOPTIMIZE=2  # Maximum Python optimizations
      - PYTHONUNBUFFERED=1  # Unbuffered output
      - PYTHONDONTWRITEBYTECODE=1  # Don't write .pyc files
      - TOKENIZER_CACHE_SIZE=1000  # Enable text caching for 95% improvement
      - WORKER_PROCESSES=4  # Multiple worker processes
      - ENABLE_GC_OPTIMIZATION=1  # Enable garbage collection optimization
      
      # Memory optimization
      - MALLOC_TRIM_THRESHOLD=131072  # Optimize memory allocation
      - MALLOC_MMAP_THRESHOLD=131072
      
      # Service configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - SERVICE_NAME=${SERVICE_NAME:-thai-tokenizer}
      - VERSION=${VERSION:-0.1.0}
    depends_on:
      meilisearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - thai-tokenizer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
    # Enable scaling
    scale: 2

  meilisearch:
    image: getmeili/meilisearch:v1.15.2
    ports:
      - "7700:7700"
    environment:
      # Core MeiliSearch configuration
      - MEILI_MASTER_KEY=${MEILISEARCH_API_KEY:-masterKey}
      - MEILI_ENV=${MEILI_ENV:-development}
      - MEILI_LOG_LEVEL=WARN  # Reduce logging overhead
      
      # Optimized Thai tokenization settings
      - MEILI_MAX_INDEXING_MEMORY=1Gb  # Optimized memory usage
      - MEILI_MAX_INDEXING_THREADS=2   # Optimized thread count
      
      # Performance settings for Thai text
      - MEILI_SNAPSHOT_DIR=/meili_data/snapshots
      - MEILI_DUMP_DIR=/meili_data/dumps
      
      # Additional performance optimizations
      - MEILI_TASK_WEBHOOK_URL=""  # Disable webhooks for performance
      - MEILI_EXPERIMENTAL_ENABLE_METRICS=false  # Disable metrics collection
    volumes:
      - meilisearch_data:/meili_data
      - meilisearch_snapshots:/meili_data/snapshots
      - meilisearch_dumps:/meili_data/dumps
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7700/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - thai-tokenizer-network
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Redis for caching (optional but recommended for production)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - thai-tokenizer-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    profiles:
      - production
      - caching

volumes:
  meilisearch_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../../data/meilisearch
  meilisearch_snapshots:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../../data/snapshots
  meilisearch_dumps:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../../data/dumps

networks:
  thai-tokenizer-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: thai-tokenizer-br
      com.docker.network.driver.mtu: 1500